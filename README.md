# llm-serving-sec-filings

Fast, reproducible LLM serving with vLLM on a single machine or Kaggle dual-T4. Includes:

OpenAI-compatible server for Llama 3.1 8B Instruct

Tiny RAG pipeline (FAISS + BGE embeddings)

Latency benchmarks (TTFT/TPOT/throughput)
